{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import hashlib\n",
    "import os\n",
    "import pyodbc\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funciones para anonimizar\n",
    "def generate_salt():\n",
    "    \"\"\"\n",
    "    Genera una cadena aleatoria (salt) para añadir a los datos antes de hashearlos.\n",
    "    \"\"\"\n",
    "    return os.urandom(16)  # 16 bytes para el salt (128 bits)\n",
    "\n",
    "def hash_with_salt(data, salt):\n",
    "    \"\"\"\n",
    "    Aplica el algoritmo SHA-512 para hashear los datos junto con el salt.\n",
    "    \"\"\"\n",
    "    data_with_salt = data.encode() + salt\n",
    "    hashed_data = hashlib.sha512(data_with_salt).hexdigest()\n",
    "    return hashed_data\n",
    "\n",
    "# Funciones para interactuar con la db\n",
    "def get_table_names(conn_str):\n",
    "    \"\"\"\n",
    "    Obtiene una lista de nombres de tablas disponibles en la base de datos.\n",
    "    \"\"\"\n",
    "    with pyodbc.connect(conn_str) as conn:\n",
    "        cursor = conn.cursor()\n",
    "        tables = [table.table_name for table in cursor.tables(tableType='TABLE')]\n",
    "        return tables\n",
    "\n",
    "def execute_query(conn_str, query):\n",
    "    \"\"\"\n",
    "    Ejecuta una consulta SQL en la base de datos y devuelve los resultados en un DataFrame de pandas.\n",
    "    \"\"\"\n",
    "    with pyodbc.connect(conn_str) as conn:\n",
    "        df = pd.read_sql_query(query, conn)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conexion a la db\n",
    "conn_str = r'DRIVER={Microsoft Access Driver (*.mdb, *.accdb)};DBQ=C:\\Users\\CityLab Biobio - DS\\Desktop\\Citylab\\datos\\Bases de datos nuevas\\Sectra\\Sectra _2017 _CCP\\BD\\07CLBB_EOD_del_GRAN_CCP.accdb;'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Obtener los nombres de las tablas disponibles en la db\n",
    "# table_names = get_table_names(conn_str)\n",
    "# print(\"Tablas disponibles:\")\n",
    "# for name in table_names:\n",
    "#     print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nombre de las tablas y columnas a anonimizar\n",
    "anon_columns = {\n",
    "    'HOGAR': ['DireccionTelefono1', 'DireccionTelefono2', 'Encuestador',],\n",
    "    'PERSONA': ['TelefonoContacto1', 'TelefonoContacto2', 'Encuestador', 'Nombre', ],\n",
    "}\n",
    "\n",
    "# Tablas que no requieren anonimizar\n",
    "direct_tables = ['VIAJES_LAB', 'Tipo Asiento']\n",
    "\n",
    "# Ruta principal para guardar los datos de salida\n",
    "save_path = 'C:\\\\Users\\\\CityLab Biobio - DS\\\\Dev\\\\CityLab_Biobio\\\\data\\\\output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Iteramos en las tablas con sus respectivas columnas\n",
    "for table, anon_cols in anon_columns.items():\n",
    "    # Query para consultar todas las columnas de la tabla\n",
    "    query = f'SELECT * FROM {table}'\n",
    "    \n",
    "    # Obtener los datos desde la db\n",
    "    df = execute_query(conn_str, query)\n",
    "\n",
    "    # Generamos un Dataframe para guardar los datos con y sin anonimizacion\n",
    "    df_hash = df[anon_cols]\n",
    "\n",
    "    # Iteramos en las columnas a anonimizar\n",
    "    for col in anon_cols:\n",
    "        # Generar un nuevo salt para la columna correspondiente\n",
    "        salt = generate_salt()\n",
    "\n",
    "        # Nuevo nombre de la columna a anonimizar\n",
    "        new_col = f'{col}_anon'\n",
    "\n",
    "        # Aplicar hash y salt a cada valor de la columna correspondiente\n",
    "        new_data = df[col].apply(lambda x: hash_with_salt(x, salt))\n",
    "\n",
    "        # Agregamos los datos a los Dataframe\n",
    "        df[new_col] = new_data\n",
    "        df_hash[new_col] = new_data\n",
    "\n",
    "    # Quitamos las columnas que se anonimizaron\n",
    "    df.drop(columns=anon_cols, inplace=True)\n",
    "\n",
    "    # Guardamos los dataframe resultantes\n",
    "    df.to_pickle(os.path.join(save_path, 'transfer', f'{table}.pkl'))\n",
    "    df_hash.to_pickle(os.path.join(save_path, 'hash', f'{table}.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportar las tablas que no requieren anonimización\n",
    "for table in direct_tables:\n",
    "    # Query para consultar todas las columnas de la tabla\n",
    "    if(' ' in table):\n",
    "        query = f\"SELECT * FROM [{table}];\"\n",
    "    else:\n",
    "        query = f\"SELECT * FROM {table};\"\n",
    "    \n",
    "    # Obtener los datos desde la db\n",
    "    df = execute_query(conn_str, query)\n",
    "\n",
    "    # Generamos un Dataframe para guardar los datos con y sin anonimizacion\n",
    "\n",
    "    df.to_pickle(os.path.join(save_path, 'transfer', f'{table}.pkl'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
